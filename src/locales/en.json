{
    "title":"Portfolio",
    "hello": "Hello! My name is",
    "name": "Diego",
    "resume": "I am a Software Development and Management Engineer. I graduated in 2022, but I have been immersed in the professional field since May 2020. Throughout my career, I have worked in various areas of my field, from QA tester to taking on developer roles, and currently serving as a Tech Leader.",
    "changeLanguage": "Change language",
    "about": "About",
    "skills":"Skills",
    "contact":"Contact",
    "projects":"Projects",
    "experience":"Experience",
    "introduction":"Introduction",
    "overview":"Overview.",
    "overviewText":"I began my professional development in May 2020 at Exos Technology, where I had the opportunity to work as an intern in the QA testing area. During this time, I acquired solid skills in unit and integration testing of software projects, as well as mastering comprehensive documentation and evidence file generation. My most notable contribution in QA was the implementation of test automation tools, such as SmartBear, Katalon, and Selenium. These tools were essential for automating software regression testing, allowing us to generate multiple scenarios and a comprehensive results matrix. This approach not only increased the efficiency of our development process, but also significantly improved the quality and consistency of the delivered software. Later on, I transitioned to the development area, where I played a key role in various projects and faced diverse challenges. At Exos, a company with a particular focus on the financial sector, I led the implementation of software solutions of various kinds; from creating simple microservices for dispute and clarification management, to developing sophisticated algorithms and implementing complex batch processes; I always actively participated in all aspects of development. My progression within the company led me to take on the role of technical leader, where, in addition to continuing to develop innovative solutions, I dedicated myself to planning (work plan generation), execution (progress review, testing), and successful delivery of all projects.",
    "frontend": "Frontend Developer",
    "backend": "Backend Developer",
    "ux": "UX/UI Design",
    "qa": "QA",
    "mySkills": "My skills",
    "techs": "Technologies.",
    "soFar": "What I've done so far...",
    "workExperience": "Work Experience.",
    "myResume": "My resume",
    "touch": "Get in touch",
    "contactTitle": "Contact.",
    "contactInfo": "Reach me",
    "yourName": "Your Name",
    "yourEmail": "Your Email",
    "yourMsg": "Your Message",
    "send": "Send",
    "sendingMsg": "Thank you. I will get back to you as soon as possible.",
    "errorMsg":"Something went wrong. Please try again.",
    "mail": "Email",
    "phone": "Phone",
    "caseStudies": "Case studies",
    "proyects": "Proyects.",
    "achievements":"Explore a selection of projects where I have acquired and put into practice new skills, enriching my experience to achieve the set goals. These projects not only reflect the work done but also the tangible impact I have achieved. Explore how my solutions have generated measurable results and have contributed to the success of both my clients and the involved teams.",
    "saleCapture": "Sales capture BBVA-AMEX",
    "saleCaptureDescription": "Undoubtedly, one of the most challenging projects I have had the opportunity to develop. Not only because of its technical and logical complexity but also due to the need to process large volumes of data. This module is part of a larger project called eBind, being the first to implement GraphQL, Apollo Federation, and Spring Boot. The decision to use GraphQL was driven by the need for a centralized service that would allow different modules and processes to access the services implemented for this project. Since sales are interconnected with other processes, the flexibility offered by the Netflix library was essential. With this independent GraphQL service core, an API Gateway with Apollo Federation was created to facilitate requests to the Sales service. Throughout the development process, different approaches had to be worked on, as the goal was to process 16k records in 3 minutes, which was ultimately achieved.",
    "kafkaMigracion": "Kafka migration",
    "kafkaMigracionDescription": "Throughout my career, I've worked on Batch projects designed to execute processes handling a large amount of data; however, at times, these approaches proved inadequate, prompting us to implement Kafka, a solution offering the necessary capacity our client required for the project. Previously, all transactions received by the client during the day were processed overnight, averaging 20 million transactions daily; the Batch process developed didn't provide the capacity to handle all these transactions in a reduced time, so we decided to adopt Kafka with the goal of processing transactions in real-time as they arrived at the database; we set an ambitious goal of processing 1000 transactions per second, which we achieved; for this project, in addition to implementing Kafka and CDC for connection to various databases (Informix, Oracle), we used Spring Boot to program the brokers and topics, enabling their scalability in a cluster environment.",
    "downloadResume": "Download my resume"
}
